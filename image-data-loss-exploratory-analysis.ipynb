{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Data Loss Exploratory Analysis","metadata":{}},{"cell_type":"markdown","source":"## Setup Environment","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # visualization\nimport seaborn as sns # visualization\n# machine learning\nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import transforms, datasets, models\n\n!pip3 install progressbar\nimport progressbar\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-10T00:04:37.866190Z","iopub.execute_input":"2021-10-10T00:04:37.866492Z","iopub.status.idle":"2021-10-10T00:04:52.903827Z","shell.execute_reply.started":"2021-10-10T00:04:37.866416Z","shell.execute_reply":"2021-10-10T00:04:52.902870Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:04:52.906057Z","iopub.execute_input":"2021-10-10T00:04:52.906396Z","iopub.status.idle":"2021-10-10T00:04:52.968450Z","shell.execute_reply.started":"2021-10-10T00:04:52.906357Z","shell.execute_reply":"2021-10-10T00:04:52.967727Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load MNIST Dataset","metadata":{}},{"cell_type":"code","source":"# import mnist dataset\nBATCH_SIZE = 250\n\ntrain_loader = torch.utils.data.DataLoader(\n    torchvision.datasets.MNIST('/kaggle/working',\n                               train=True,\n                               download=True,\n                               transform=torchvision.transforms.ToTensor()),\n    batch_size=BATCH_SIZE,shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(\n    torchvision.datasets.MNIST('/kaggle/working',\n                               train=False,\n                               download=True,\n                               transform=torchvision.transforms.ToTensor()),\n    batch_size=BATCH_SIZE,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:04:52.971334Z","iopub.execute_input":"2021-10-10T00:04:52.971562Z","iopub.status.idle":"2021-10-10T00:04:54.669494Z","shell.execute_reply.started":"2021-10-10T00:04:52.971539Z","shell.execute_reply":"2021-10-10T00:04:54.668801Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## MNIST Classifier","metadata":{}},{"cell_type":"code","source":"class BasicClassifier(nn.Module):\n    def __init__(self,num_classes) -> None:\n        self.num_classes = num_classes\n        super(BasicClassifier, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1,64,kernel_size=7),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64,128,kernel_size=11),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128,182,kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(182,256,kernel_size=5),\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096,2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048,1024),\n            nn.ReLU(inplace=True),\n            nn.Linear(1024,num_classes),\n        )\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:04:54.671669Z","iopub.execute_input":"2021-10-10T00:04:54.672450Z","iopub.status.idle":"2021-10-10T00:04:54.682939Z","shell.execute_reply.started":"2021-10-10T00:04:54.672411Z","shell.execute_reply":"2021-10-10T00:04:54.682175Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Metrics Class","metadata":{}},{"cell_type":"code","source":"class Metrics:\n    def __init__(self):\n        pass\n    \n    def update_confusion_matrix(self, outputs: torch.Tensor, labels: torch.Tensor) -> None:       \n        for (guess,label) in zip(outputs.argmax(1),labels):\n            self.confusion_matrix[guess,label] += 1\n            \n    def get_confusion_matrix(self,norm=False) -> np.array:\n        if norm:\n            return self.confusion_matrix / self.confusion_matrix.sum()\n        return self.confusion_matrix\n    \n    def reset_confusion_matrix(self,num_classes: int) -> None:\n        self.confusion_matrix = np.zeros((num_classes,num_classes))\n    \n    def classification_metrics(self,print_=False) -> tuple:\n        s = \"Accuracy: {}\\nPrecision: {}\\nRecall: {}\\nf1-score: {}\\nSupport: {}\".format(self.accuracy(),self.precision(),self.recall(),self.f1_score(),self.confusion_matrix.sum())\n        if print_:\n            print(s)\n        return [self.accuracy(),self.precision(),self.recall(),self.f1_score(),self.confusion_matrix.sum()]\n    def accuracy(self) -> int:\n        dim = self.confusion_matrix.shape[0]\n        correct = 0.0\n        total = self.confusion_matrix.sum()\n        for i in range(dim):\n            correct += self.confusion_matrix[i,i]\n        return correct/total\n    def precision(self) -> int:\n        fp = 0\n        tp = 0\n        for i in range(len(self.confusion_matrix)):\n            for j in range(len(self.confusion_matrix)):\n                if i == j:\n                    tp += self.confusion_matrix[i,j]\n                if i < j:\n                    fp += self.confusion_matrix[i,j]\n        return tp / (tp + fp)\n    def recall(self) -> int:\n        fn = 0\n        tp = 0\n        for i in range(len(self.confusion_matrix)):\n            for j in range(len(self.confusion_matrix)):\n                if i == j:\n                    tp += self.confusion_matrix[i,j]\n                if i > j:\n                    fn += self.confusion_matrix[i,j]\n        return tp / (tp + fn)\n    def f1_score(self) -> int:\n        p = self.precision()\n        r = self.recall()\n        return 2.0*(p*r)/(p+r)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:04:54.684309Z","iopub.execute_input":"2021-10-10T00:04:54.684592Z","iopub.status.idle":"2021-10-10T00:04:54.701744Z","shell.execute_reply.started":"2021-10-10T00:04:54.684551Z","shell.execute_reply":"2021-10-10T00:04:54.701094Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = BasicClassifier(10)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:04:54.703339Z","iopub.execute_input":"2021-10-10T00:04:54.703720Z","iopub.status.idle":"2021-10-10T00:05:00.540543Z","shell.execute_reply.started":"2021-10-10T00:04:54.703603Z","shell.execute_reply":"2021-10-10T00:05:00.539652Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"metric = Metrics()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:05:00.541738Z","iopub.execute_input":"2021-10-10T00:05:00.541997Z","iopub.status.idle":"2021-10-10T00:05:00.546363Z","shell.execute_reply.started":"2021-10-10T00:05:00.541961Z","shell.execute_reply":"2021-10-10T00:05:00.545592Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(),lr=3e-5)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:05:00.547709Z","iopub.execute_input":"2021-10-10T00:05:00.548131Z","iopub.status.idle":"2021-10-10T00:05:00.560586Z","shell.execute_reply.started":"2021-10-10T00:05:00.548068Z","shell.execute_reply":"2021-10-10T00:05:00.559814Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"widgets = [\n    ' [', progressbar.Timer(), '] ',\n    progressbar.Percentage(), ' ',\n    progressbar.Bar(),\n    ' (', progressbar.ETA(), ') ',\n]","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:05:00.562117Z","iopub.execute_input":"2021-10-10T00:05:00.562534Z","iopub.status.idle":"2021-10-10T00:05:00.570414Z","shell.execute_reply.started":"2021-10-10T00:05:00.562496Z","shell.execute_reply":"2021-10-10T00:05:00.569475Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"code","source":"# training\nNUM_EPOCHS = 10\nbar = progressbar.ProgressBar(NUM_EPOCHS*len(train_loader),widgets=widgets).start()\nfor epoch in range(NUM_EPOCHS):\n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(train_loader):\n        optimizer.zero_grad()\n        outputs = model(inputs.to(device))\n        loss = criterion(outputs, labels.to(device))\n        loss.backward()\n        optimizer.step()\n        # statistics\n        # progressbar\n        bar.update(epoch*len(train_loader)+i)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-10T00:05:00.573635Z","iopub.execute_input":"2021-10-10T00:05:00.573950Z","iopub.status.idle":"2021-10-10T00:06:42.589363Z","shell.execute_reply.started":"2021-10-10T00:05:00.573916Z","shell.execute_reply":"2021-10-10T00:06:42.588620Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Test Model","metadata":{}},{"cell_type":"code","source":"# testing\nmetric.reset_confusion_matrix(10)\nbar = progressbar.ProgressBar(len(test_loader),widgets=widgets).start()\nwith torch.no_grad():\n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(test_loader):\n        outputs = model(inputs.to(device))\n        # statistics\n        metric.update_confusion_matrix(outputs.to('cpu'),labels)\n        # progressbar\n        bar.update(i)\nm = metric.get_confusion_matrix(norm=True)\nsns.heatmap(m,square=True,cmap='Greys')\nplt.show()\nmetric.classification_metrics(print_=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:06:42.590671Z","iopub.execute_input":"2021-10-10T00:06:42.590999Z","iopub.status.idle":"2021-10-10T00:06:44.217204Z","shell.execute_reply.started":"2021-10-10T00:06:42.590960Z","shell.execute_reply":"2021-10-10T00:06:44.216521Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Create Data Loss Class\n\n\n","metadata":{}},{"cell_type":"code","source":"class DataLoss:\n    def __init__(self):\n        pass\n    def random_per_pixel(self,inputs: torch.Tensor,ppp: float=0.0) -> torch.Tensor:\n        # ppp: proportion per pixel\n        lossyinputs = torch.clone(inputs)\n        mask = torch.Tensor(np.random.rand(inputs.shape[0],inputs.shape[1],inputs.shape[2],inputs.shape[3]))\n        lossyinputs = lossyinputs * (mask > ppp)\n        return lossyinputs\n    \n    def random_per_img(self,inputs: torch.Tensor,ppp: float=0.0) -> torch.Tensor:\n        if ppp < 0.0001:\n            return inputs\n        lossyinputs = torch.clone(inputs)\n        mask = np.random.rand(inputs.shape[0],int(inputs.shape[2]*inputs.shape[3]*ppp))*inputs.shape[2]*inputs.shape[3]\n        x = mask%inputs.shape[2]\n        y = mask/inputs.shape[2]\n        for batch in range(inputs.shape[0]):\n            for channel in range(inputs.shape[1]):\n                for i in range(x.shape[1]):\n                    lossyinputs[batch,channel,int(x[batch,i]),int(y[batch,i])] = 0\n        return lossyinputs  \ndloss = DataLoss()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:06:44.218455Z","iopub.execute_input":"2021-10-10T00:06:44.218802Z","iopub.status.idle":"2021-10-10T00:06:44.229735Z","shell.execute_reply.started":"2021-10-10T00:06:44.218763Z","shell.execute_reply":"2021-10-10T00:06:44.228635Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plt.imshow(inputs[0][0],cmap='Greys')\nplt.title('raw')\nplt.show()\nplt.imshow(dloss.random_per_pixel(inputs,0.5)[0][0],cmap='Greys')\nplt.title('random_per_pixel')\nplt.show()\nplt.imshow(dloss.random_per_img(inputs,0.5)[0][0],cmap='Greys')\nplt.title('random_per_img')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:06:44.230845Z","iopub.execute_input":"2021-10-10T00:06:44.231188Z","iopub.status.idle":"2021-10-10T00:06:45.885364Z","shell.execute_reply.started":"2021-10-10T00:06:44.231150Z","shell.execute_reply":"2021-10-10T00:06:45.884728Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Test Model on Lossy Data","metadata":{}},{"cell_type":"markdown","source":"### DataLoss::random_per_pixel()","metadata":{}},{"cell_type":"code","source":"# Testing on DataLoss::random_per_pixel()\nloss_stats = {}\npercents = [x/10.0 for x in range(10)] + [0.95,0.99] # input parameters to DataLoss::random_ppp()\nbar = progressbar.ProgressBar(len(percents),widgets=widgets).start()\nfor cc, ppp in enumerate(percents):\n    metric.reset_confusion_matrix(10)\n    with torch.no_grad():\n        running_loss = 0.0\n        for i, (inputs, labels) in enumerate(test_loader):\n            outputs = model(dloss.random_per_pixel(inputs,ppp).to(device)) # apply data loss\n            # statistics\n            metric.update_confusion_matrix(outputs.to('cpu'),labels)\n            # progressbar\n    bar.update(cc)\n    loss_stats[ppp] = metric.classification_metrics()\nprint(loss_stats)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:06:45.886452Z","iopub.execute_input":"2021-10-10T00:06:45.886738Z","iopub.status.idle":"2021-10-10T00:07:02.647763Z","shell.execute_reply.started":"2021-10-10T00:06:45.886702Z","shell.execute_reply":"2021-10-10T00:07:02.646643Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Metrics on DataLoss::random_per_pixel()\nleg = ['accuracy','precision','recall']\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,0],) # accuracy\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,1]) # precision\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,2]) # recall\nplt.legend(leg)\nplt.xlabel('% loss')\nplt.title('DataLoss::random_per_pixel()')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:07:02.648950Z","iopub.execute_input":"2021-10-10T00:07:02.649295Z","iopub.status.idle":"2021-10-10T00:07:02.931213Z","shell.execute_reply.started":"2021-10-10T00:07:02.649256Z","shell.execute_reply":"2021-10-10T00:07:02.930467Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### DataLoss::random_per_img()","metadata":{}},{"cell_type":"code","source":"# Testing on DataLoss::random_per_img()\nloss_stats = {}\npercents = [x/10.0 for x in range(0,10)] + [0.95] # input parameters to DataLoss::random_per_img()\nbar = progressbar.ProgressBar(len(percents),widgets=widgets).start()\nfor cc, ppp in enumerate(percents):\n    metric.reset_confusion_matrix(10)\n    with torch.no_grad():\n        running_loss = 0.0\n        for i, (inputs, labels) in enumerate(test_loader):\n            outputs = model(dloss.random_per_img(inputs,ppp).to(device)) # apply data loss\n            # statistics\n            metric.update_confusion_matrix(outputs.to('cpu'),labels)\n            # progressbar\n    bar.update(cc)\n    loss_stats[ppp] = metric.classification_metrics()\nprint(loss_stats)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:07:02.932605Z","iopub.execute_input":"2021-10-10T00:07:02.932888Z","iopub.status.idle":"2021-10-10T00:15:27.860648Z","shell.execute_reply.started":"2021-10-10T00:07:02.932852Z","shell.execute_reply":"2021-10-10T00:15:27.859608Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Metrics on DataLoss::random_per_img()\nleg = ['accuracy','precision','recall']\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,0],) # accuracy\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,1]) # precision\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,2]) # recall\nplt.legend(leg)\nplt.xlabel('% loss')\nplt.title('DataLoss::random_per_img()')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:15:27.861838Z","iopub.execute_input":"2021-10-10T00:15:27.862573Z","iopub.status.idle":"2021-10-10T00:15:28.121535Z","shell.execute_reply.started":"2021-10-10T00:15:27.862532Z","shell.execute_reply":"2021-10-10T00:15:28.120844Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Feature Map\nhttps://androidkt.com/how-to-visualize-feature-maps-in-convolutional-neural-networks-using-pytorch/","metadata":{}},{"cell_type":"code","source":"no_of_layers=0\nconv_layers=[]\n \nmodel_children=list(model.children())\n \nfor child in model_children:\n    if type(child)==nn.Conv2d:\n        no_of_layers+=1\n        conv_layers.append(child)\n    elif type(child)==nn.Sequential:\n        for layer in child.children():\n            if type(layer)==nn.Conv2d:\n                no_of_layers+=1\n                conv_layers.append(layer)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:46:41.196542Z","iopub.execute_input":"2021-10-10T00:46:41.197218Z","iopub.status.idle":"2021-10-10T00:46:41.203191Z","shell.execute_reply.started":"2021-10-10T00:46:41.197181Z","shell.execute_reply":"2021-10-10T00:46:41.201960Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"#### Feature Map without DataLoss","metadata":{}},{"cell_type":"code","source":"(inputs,labels) = next(iter(test_loader))\nimg = inputs[0:]\nresults = [conv_layers[0](img.to(device))]\nfor i in range(1, len(conv_layers)):\n    results.append(conv_layers[i](results[-1]))\noutputs = results","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:48:25.121146Z","iopub.execute_input":"2021-10-10T00:48:25.121438Z","iopub.status.idle":"2021-10-10T00:48:25.156996Z","shell.execute_reply.started":"2021-10-10T00:48:25.121407Z","shell.execute_reply":"2021-10-10T00:48:25.156239Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img[0,0].to('cpu'))\nfor num_layer in range(len(outputs)):\n    plt.figure(figsize=(50, 10))\n    layer_viz = outputs[num_layer][0, :, :, :]\n    layer_viz = layer_viz.data\n    print(\"Layer \",num_layer+1)\n    for i, filter in enumerate(layer_viz.to('cpu')):\n        if i == 8: \n            break\n        plt.subplot(2, 8, i + 1)\n        plt.imshow(filter, cmap='gray')\n        plt.axis(\"off\")\n    plt.show()\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:48:26.679479Z","iopub.execute_input":"2021-10-10T00:48:26.679799Z","iopub.status.idle":"2021-10-10T00:48:28.949537Z","shell.execute_reply.started":"2021-10-10T00:48:26.679765Z","shell.execute_reply":"2021-10-10T00:48:28.948846Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"#### Feature Map with DataLoss","metadata":{}},{"cell_type":"code","source":"img = dloss.random_per_img(img,0.9)\nresults = [conv_layers[0](img.to(device))]\nfor i in range(1, len(conv_layers)):\n    results.append(conv_layers[i](results[-1]))\noutputs = results","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:51:46.721780Z","iopub.execute_input":"2021-10-10T00:51:46.722418Z","iopub.status.idle":"2021-10-10T00:51:49.140565Z","shell.execute_reply.started":"2021-10-10T00:51:46.722378Z","shell.execute_reply":"2021-10-10T00:51:49.139844Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img[0,0].to('cpu'))\nfor num_layer in range(len(outputs)):\n    plt.figure(figsize=(50, 10))\n    layer_viz = outputs[num_layer][0, :, :, :]\n    layer_viz = layer_viz.data\n    print(\"Layer \",num_layer+1)\n    for i, filter in enumerate(layer_viz.to('cpu')):\n        if i == 8: \n            break\n        plt.subplot(2, 8, i + 1)\n        plt.imshow(filter, cmap='gray')\n        plt.axis(\"off\")\n    plt.show()\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T00:51:49.142314Z","iopub.execute_input":"2021-10-10T00:51:49.142609Z","iopub.status.idle":"2021-10-10T00:51:51.458465Z","shell.execute_reply.started":"2021-10-10T00:51:49.142576Z","shell.execute_reply":"2021-10-10T00:51:51.457648Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}