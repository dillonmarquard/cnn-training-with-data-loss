{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Data Loss Exploratory Analysis","metadata":{}},{"cell_type":"markdown","source":"## Setup Environment","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # visualization\nimport seaborn as sns # visualization\n# machine learning\nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import transforms, datasets, models\n\n!pip3 install progressbar\nimport progressbar\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-11T23:25:58.463516Z","iopub.execute_input":"2021-10-11T23:25:58.463899Z","iopub.status.idle":"2021-10-11T23:26:13.821066Z","shell.execute_reply.started":"2021-10-11T23:25:58.463801Z","shell.execute_reply":"2021-10-11T23:26:13.820228Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:13.823222Z","iopub.execute_input":"2021-10-11T23:26:13.823508Z","iopub.status.idle":"2021-10-11T23:26:13.879351Z","shell.execute_reply.started":"2021-10-11T23:26:13.823470Z","shell.execute_reply":"2021-10-11T23:26:13.878568Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load MNIST Dataset","metadata":{}},{"cell_type":"code","source":"# import mnist dataset\nBATCH_SIZE = 250\n\ntrain_loader = torch.utils.data.DataLoader(\n    torchvision.datasets.MNIST('/kaggle/working',\n                               train=True,\n                               download=True,\n                               transform=torchvision.transforms.ToTensor()),\n    batch_size=BATCH_SIZE,shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(\n    torchvision.datasets.MNIST('/kaggle/working',\n                               train=False,\n                               download=True,\n                               transform=torchvision.transforms.ToTensor()),\n    batch_size=BATCH_SIZE,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:13.880954Z","iopub.execute_input":"2021-10-11T23:26:13.881595Z","iopub.status.idle":"2021-10-11T23:26:15.210659Z","shell.execute_reply.started":"2021-10-11T23:26:13.881557Z","shell.execute_reply":"2021-10-11T23:26:15.209937Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## MNIST Classifier / Baseline Model","metadata":{}},{"cell_type":"code","source":"class BasicClassifier(nn.Module):\n    def __init__(self,num_classes) -> None:\n        self.num_classes = num_classes\n        super(BasicClassifier, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1,64,kernel_size=7),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64,128,kernel_size=11),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128,182,kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(182,256,kernel_size=5),\n        )\n        self.classifier = nn.Sequential(\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096,2048),\n            nn.ReLU(inplace=True),\n            nn.Linear(2048,1024),\n            nn.ReLU(inplace=True),\n            nn.Linear(1024,num_classes),\n        )\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:15.212646Z","iopub.execute_input":"2021-10-11T23:26:15.213364Z","iopub.status.idle":"2021-10-11T23:26:15.223429Z","shell.execute_reply.started":"2021-10-11T23:26:15.213325Z","shell.execute_reply":"2021-10-11T23:26:15.222453Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Metrics Class","metadata":{}},{"cell_type":"code","source":"class Metrics:\n    def __init__(self):\n        pass\n    \n    def update_confusion_matrix(self, outputs: torch.Tensor, labels: torch.Tensor) -> None:       \n        for (guess,label) in zip(outputs.argmax(1),labels):\n            self.confusion_matrix[guess,label] += 1\n            \n    def get_confusion_matrix(self,norm=False) -> np.array:\n        if norm:\n            return self.confusion_matrix / self.confusion_matrix.sum()\n        return self.confusion_matrix\n    \n    def reset_confusion_matrix(self,num_classes: int) -> None:\n        self.confusion_matrix = np.zeros((num_classes,num_classes))\n    \n    def classification_metrics(self,print_=False) -> tuple:\n        s = \"Accuracy: {}\\nPrecision: {}\\nRecall: {}\\nf1-score: {}\\nSupport: {}\".format(self.accuracy(),self.precision(),self.recall(),self.f1_score(),self.confusion_matrix.sum())\n        if print_:\n            print(s)\n        return [self.accuracy(),self.precision(),self.recall(),self.f1_score(),self.confusion_matrix.sum()]\n    def accuracy(self) -> int:\n        dim = self.confusion_matrix.shape[0]\n        correct = 0.0\n        total = self.confusion_matrix.sum()\n        for i in range(dim):\n            correct += self.confusion_matrix[i,i]\n        return correct/total\n    def precision(self) -> int:\n        fp = 0\n        tp = 0\n        for i in range(len(self.confusion_matrix)):\n            for j in range(len(self.confusion_matrix)):\n                if i == j:\n                    tp += self.confusion_matrix[i,j]\n                if i < j:\n                    fp += self.confusion_matrix[i,j]\n        return tp / (tp + fp)\n    def recall(self) -> int:\n        fn = 0\n        tp = 0\n        for i in range(len(self.confusion_matrix)):\n            for j in range(len(self.confusion_matrix)):\n                if i == j:\n                    tp += self.confusion_matrix[i,j]\n                if i > j:\n                    fn += self.confusion_matrix[i,j]\n        return tp / (tp + fn)\n    def f1_score(self) -> int:\n        p = self.precision()\n        r = self.recall()\n        return 2.0*(p*r)/(p+r)\n    \n    def feature_map(self,inputs: torch.Tensor,model,print_=False):\n        no_of_layers=0\n        conv_layers=[]\n\n        model_children=list(model.children())\n\n        for child in model_children:\n            if type(child)==nn.Conv2d:\n                conv_layers.append(child)\n            elif type(child) == nn.Sequential:\n                for layer in child.children():\n                    if type(layer) == nn.Conv2d:\n                        conv_layers.append(layer)\n#         (inputs,labels) = next(iter(test_loader))\n        results = [conv_layers[0](inputs.to(device))]\n        for i in range(1, len(conv_layers)):\n            results.append(conv_layers[i](results[-1]))\n        outputs = results\n        if print_:\n            plt.imshow(inputs[0,0].to('cpu'),cmap='Greys')\n            plt.show()\n            for num_layer in range(len(outputs)):\n                plt.figure(figsize=(50, 10))\n                layer_viz = outputs[num_layer][0, :, :, :]\n                layer_viz = layer_viz.data\n#                 print(\"Layer \",num_layer+1)\n                for i, filter in enumerate(layer_viz.to('cpu')):\n                    if i == 8: \n                        break\n                    plt.subplot(2, 8, i + 1)\n                    plt.imshow(filter, cmap='gray')\n                    plt.axis(\"off\")\n                plt.show()\n                plt.close()\n        return results\n    \n    def feature_map_diff(map1,map1_loss) -> np.array:\n        pass\nmetric = Metrics()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:15.224675Z","iopub.execute_input":"2021-10-11T23:26:15.224930Z","iopub.status.idle":"2021-10-11T23:26:15.248096Z","shell.execute_reply.started":"2021-10-11T23:26:15.224896Z","shell.execute_reply":"2021-10-11T23:26:15.247448Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Data Loss Class\n\n\n","metadata":{}},{"cell_type":"code","source":"class DataLoss:\n    def __init__(self):\n        pass\n    def random_per_pixel(self,inputs: torch.Tensor,ppp: float=0.0) -> torch.Tensor:\n        # ppp: proportion per pixel\n        lossyinputs = torch.clone(inputs)\n        mask = torch.Tensor(np.random.rand(inputs.shape[0],inputs.shape[1],inputs.shape[2],inputs.shape[3]))\n        lossyinputs = lossyinputs * (mask > ppp)\n        return lossyinputs\n    \n    def random_per_img(self,inputs: torch.Tensor,ppp: float=0.0) -> torch.Tensor:\n        if int(inputs.shape[2]*inputs.shape[3]*ppp) < 1:\n            return inputs\n        if ppp > 1.0:\n            ppp = 1.0\n        num_loss = int(inputs.shape[2]*inputs.shape[3]*ppp)\n        lossyinputs = torch.clone(inputs)\n        mask = np.concatenate((np.zeros((inputs.shape[0],num_loss)),np.ones((inputs.shape[0],int(inputs.shape[2]*inputs.shape[3] - num_loss)))),axis=1)\n        for i in range(inputs.shape[0]):\n            np.random.shuffle(mask[i])\n        mask = torch.Tensor(mask.reshape((inputs.shape[0],inputs.shape[1],inputs.shape[2],inputs.shape[3])))\n        lossyinputs *= mask\n        return lossyinputs  \ndloss = DataLoss()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:15.249133Z","iopub.execute_input":"2021-10-11T23:26:15.249898Z","iopub.status.idle":"2021-10-11T23:26:15.262347Z","shell.execute_reply.started":"2021-10-11T23:26:15.249868Z","shell.execute_reply":"2021-10-11T23:26:15.261245Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"inputs = next(iter(train_loader))[0]\nplt.imshow(inputs[0][0],cmap='Greys')\nplt.title('raw')\nplt.show()\nplt.imshow(dloss.random_per_pixel(inputs,0.5)[0][0],cmap='Greys')\nplt.title('random_per_pixel')\nplt.show()\nplt.imshow(dloss.random_per_img(inputs,0.5)[0][0],cmap='Greys')\nplt.title('random_per_img')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:15.263808Z","iopub.execute_input":"2021-10-11T23:26:15.264110Z","iopub.status.idle":"2021-10-11T23:26:15.852970Z","shell.execute_reply.started":"2021-10-11T23:26:15.264075Z","shell.execute_reply":"2021-10-11T23:26:15.852326Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Model trained on unaltered data","metadata":{}},{"cell_type":"code","source":"model_unaltered = BasicClassifier(10)\nmodel_unaltered.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_unaltered.parameters(),lr=3e-5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:15.854215Z","iopub.execute_input":"2021-10-11T23:26:15.854443Z","iopub.status.idle":"2021-10-11T23:26:21.466496Z","shell.execute_reply.started":"2021-10-11T23:26:15.854412Z","shell.execute_reply":"2021-10-11T23:26:21.465744Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"widgets = [\n    ' [', progressbar.Timer(), '] ',\n    progressbar.Percentage(), ' ',\n    progressbar.Bar(),\n    ' (', progressbar.ETA(), ') ',\n]","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:26:21.467724Z","iopub.execute_input":"2021-10-11T23:26:21.467976Z","iopub.status.idle":"2021-10-11T23:26:21.473772Z","shell.execute_reply.started":"2021-10-11T23:26:21.467945Z","shell.execute_reply":"2021-10-11T23:26:21.473014Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Train model_unaltered on Unaltered Data","metadata":{}},{"cell_type":"code","source":"# training\n# find best number of epochs\nNUM_EPOCHS = 10\nbar = progressbar.ProgressBar(NUM_EPOCHS*len(train_loader),widgets=widgets).start()\nfor epoch in range(NUM_EPOCHS):\n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(train_loader):\n        optimizer.zero_grad()\n        outputs = model_unaltered(inputs.to(device))\n        loss = criterion(outputs, labels.to(device))\n        loss.backward()\n        optimizer.step()\n        # statistics\n        # progressbar\n        bar.update(epoch*len(train_loader)+i)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-11T23:26:21.476957Z","iopub.execute_input":"2021-10-11T23:26:21.477228Z","iopub.status.idle":"2021-10-11T23:28:03.470364Z","shell.execute_reply.started":"2021-10-11T23:26:21.477204Z","shell.execute_reply":"2021-10-11T23:28:03.469638Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Test model_unaltered on Unaltered Data","metadata":{}},{"cell_type":"code","source":"# testing\nmetric.reset_confusion_matrix(10)\nbar = progressbar.ProgressBar(len(test_loader),widgets=widgets).start()\nwith torch.no_grad():\n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(test_loader):\n        outputs = model_unaltered(inputs.to(device))\n        # statistics\n        metric.update_confusion_matrix(outputs.to('cpu'),labels)\n        # progressbar\n        bar.update(i)\nm = metric.get_confusion_matrix(norm=True)\nsns.heatmap(m,square=True,cmap='Greys')\nplt.show()\nmetric.classification_metrics(print_=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:28:03.471697Z","iopub.execute_input":"2021-10-11T23:28:03.471946Z","iopub.status.idle":"2021-10-11T23:28:05.087094Z","shell.execute_reply.started":"2021-10-11T23:28:03.471913Z","shell.execute_reply":"2021-10-11T23:28:05.086433Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Test model_unaltered on Lossy Data","metadata":{}},{"cell_type":"markdown","source":"### DataLoss::random_per_img()","metadata":{}},{"cell_type":"code","source":"loss_stats = {}\npercents = [x/10.0 for x in range(0,10)] + [0.95] # input parameters to DataLoss::random_per_img()\nbar = progressbar.ProgressBar(len(percents),widgets=widgets).start()\nfor cc, ppp in enumerate(percents):\n    metric.reset_confusion_matrix(10)\n    with torch.no_grad():\n        running_loss = 0.0\n        for i, (inputs, labels) in enumerate(test_loader):\n            outputs = model_unaltered(dloss.random_per_img(inputs,ppp).to(device)) # apply data loss\n            # statistics\n            metric.update_confusion_matrix(outputs.to('cpu'),labels)\n            # progressbar\n    bar.update(cc)\n    loss_stats[ppp] = metric.classification_metrics()\n\nleg = ['accuracy','precision','recall']\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,0],) # accuracy\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,1]) # precision\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,2]) # recall\nplt.legend(leg)\nplt.xlabel('% loss')\nplt.title('Baseline Model trained on unaltered data DataLoss::random_per_img()')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:28:25.658169Z","iopub.execute_input":"2021-10-11T23:28:25.658494Z","iopub.status.idle":"2021-10-11T23:28:41.546481Z","shell.execute_reply.started":"2021-10-11T23:28:25.658454Z","shell.execute_reply":"2021-10-11T23:28:41.545785Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Feature Map\nhttps://androidkt.com/how-to-visualize-feature-maps-in-convolutional-neural-networks-using-pytorch/","metadata":{}},{"cell_type":"markdown","source":"## Feature Map without DataLoss","metadata":{}},{"cell_type":"code","source":"# (inputs,labels) = next(iter(test_loader))\n# res_full = metric.feature_map(inputs[0:1],model,print_=True)\n# print(model(inputs[0:1].to(device)).to('cpu').argmax())","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:28:41.548300Z","iopub.execute_input":"2021-10-11T23:28:41.548553Z","iopub.status.idle":"2021-10-11T23:28:41.552728Z","shell.execute_reply.started":"2021-10-11T23:28:41.548517Z","shell.execute_reply":"2021-10-11T23:28:41.551917Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Feature Map with DataLoss","metadata":{}},{"cell_type":"code","source":"# (inputs,labels) = next(iter(test_loader))\n# loss_inputs = dloss.random_per_img(inputs[0:1],.75)\n# res_dloss = metric.feature_map(loss_inputs,model,print_=True)\n# print(model(loss_inputs.to(device)).to('cpu').argmax())","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:28:41.554017Z","iopub.execute_input":"2021-10-11T23:28:41.554306Z","iopub.status.idle":"2021-10-11T23:28:41.562097Z","shell.execute_reply.started":"2021-10-11T23:28:41.554271Z","shell.execute_reply":"2021-10-11T23:28:41.561459Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Model Trained on Lossy Data","metadata":{}},{"cell_type":"code","source":"model_lossy_1 = BasicClassifier(10)\nmodel_lossy_1.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_lossy_1.parameters(),lr=3e-5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:28:41.563073Z","iopub.execute_input":"2021-10-11T23:28:41.563428Z","iopub.status.idle":"2021-10-11T23:28:41.990673Z","shell.execute_reply.started":"2021-10-11T23:28:41.563392Z","shell.execute_reply":"2021-10-11T23:28:41.989631Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Train model_lossy_1 on Lossy Data : loss = 50%","metadata":{}},{"cell_type":"code","source":"# training\n# find best number of epochs\nNUM_EPOCHS = 10\nbar = progressbar.ProgressBar(NUM_EPOCHS*len(train_loader),widgets=widgets).start()\nfor epoch in range(NUM_EPOCHS):\n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(train_loader):\n        optimizer.zero_grad()\n        outputs = model_lossy_1(dloss.random_per_img(inputs,0.5).to(device))\n        loss = criterion(outputs, labels.to(device))\n        loss.backward()\n        optimizer.step()\n        # statistics\n        # progressbar\n        bar.update(epoch*len(train_loader)+i)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:28:41.992782Z","iopub.execute_input":"2021-10-11T23:28:41.993096Z","iopub.status.idle":"2021-10-11T23:30:25.221955Z","shell.execute_reply.started":"2021-10-11T23:28:41.993056Z","shell.execute_reply":"2021-10-11T23:30:25.221232Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Test model_lossy_1 on Lossy Data","metadata":{}},{"cell_type":"code","source":"# Testing on DataLoss::random_per_pixel()\nloss_stats = {}\npercents = [x/10.0 for x in range(10)] + [0.95,0.99] # input parameters to DataLoss::random_ppp()\nbar = progressbar.ProgressBar(len(percents),widgets=widgets).start()\nfor cc, ppp in enumerate(percents):\n    metric.reset_confusion_matrix(10)\n    with torch.no_grad():\n        running_loss = 0.0\n        for i, (inputs, labels) in enumerate(test_loader):\n            outputs = model_lossy_1(dloss.random_per_img(inputs,ppp).to(device)) # apply data loss\n            # statistics\n            metric.update_confusion_matrix(outputs.to('cpu'),labels)\n            # progressbar\n    bar.update(cc)\n    loss_stats[ppp] = metric.classification_metrics()\n\nleg = ['accuracy','precision','recall']\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,0],) # accuracy\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,1]) # precision\nsns.lineplot(x=list(loss_stats.keys()),y=np.array(list(loss_stats.values()),dtype=float)[:,2]) # recall\nplt.legend(leg)\nplt.xlabel('% loss')\nplt.title('Baseline Model trained on lossy data DataLoss::random_per_img()')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:30:25.223297Z","iopub.execute_input":"2021-10-11T23:30:25.223538Z","iopub.status.idle":"2021-10-11T23:30:42.315707Z","shell.execute_reply.started":"2021-10-11T23:30:25.223504Z","shell.execute_reply":"2021-10-11T23:30:42.315023Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Test model_lossy_1 on Unaltered Data","metadata":{}},{"cell_type":"code","source":"# Testing on DataLoss::random_per_pixel()\nmetric.reset_confusion_matrix(10)\nbar = progressbar.ProgressBar(len(test_loader),widgets=widgets).start()\nwith torch.no_grad():\n    running_loss = 0.0\n    for i, (inputs, labels) in enumerate(test_loader):\n        outputs = model_lossy_1(inputs.to(device))\n        # statistics\n        metric.update_confusion_matrix(outputs.to('cpu'),labels)\n        # progressbar\n        bar.update(i)\nm = metric.get_confusion_matrix(norm=True)\nsns.heatmap(m,square=True,cmap='Greys')\nplt.show()\nmetric.classification_metrics(print_=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T23:30:42.317016Z","iopub.execute_input":"2021-10-11T23:30:42.317304Z","iopub.status.idle":"2021-10-11T23:30:43.931899Z","shell.execute_reply.started":"2021-10-11T23:30:42.317268Z","shell.execute_reply":"2021-10-11T23:30:43.931201Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}